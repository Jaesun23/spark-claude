---
name: spark-implement
description: Quality-driven implementation workflow orchestrating multiple specialists through phases with strict quality gates
type: command
requires: implementer-spark, tester-spark, documenter-spark
---

# /spark-implement - Quality-Driven Implementation Command

**Purpose**: Orchestrates a complete development pipeline where quality isn't just checked but cultivated at every step, ensuring deliverables that inspire confidence and pride.

## Decision Framework (2í˜¸ì˜ íŒë‹¨ ê¸°ì¤€)

2í˜¸ê°€ ì´ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ë•Œ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ê³  í–‰ë™í•©ë‹ˆë‹¤:

### Quality vs Velocity Balance (ë¯¸ë¬˜í•œ ì¡°ì ˆì´ë‚˜ ê· í˜•ì˜ ë¬˜)

**ìƒí™©ë³„ ì˜ì‚¬ê²°ì •:**
- **ê¸´ê¸‰í•œ ìš”ì²­**: í’ˆì§ˆ ê²Œì´íŠ¸ëŠ” ìœ ì§€í•˜ë˜, í•µì‹¬ ê¸°ëŠ¥ì— ì§‘ì¤‘
- **ë³µì¡í•œ ìš”ì²­**: ì‹œê°„ì„ ë” íˆ¬ìí•´ì„œ thorough ê²€ì¦
- **ì¼ë°˜ì  ìš”ì²­**: ê· í˜•ì¡íŒ ì ‘ê·¼ìœ¼ë¡œ í’ˆì§ˆê³¼ ì†ë„ ëª¨ë‘ í™•ë³´

**êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨:**
- ëª¨ë“  í’ˆì§ˆ ê²Œì´íŠ¸ëŠ” ë°˜ë“œì‹œ í†µê³¼ (violations_total = 0)
- ë‹¨, ì‹œê°„ ì••ë°•ì´ ìˆì„ ë•ŒëŠ” documentationì„ ê°„ì†Œí™” ê°€ëŠ¥
- ë³µì¡ë„ê°€ ë†’ì„ ë•ŒëŠ” ì¶”ê°€ validation ë‹¨ê³„ í¬í•¨

### Implementation Philosophy

**ì½”ë“œ í’ˆì§ˆ ì›ì¹™:**
1. **Elegance over Cleverness**: ë³µì¡í•œ ë¡œì§ë³´ë‹¤ëŠ” ì½ê¸° ì‰¬ìš´ ì½”ë“œ
2. **Proactive Error Handling**: ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê³ ë ¤í•œ ì˜ˆì™¸ ì²˜ë¦¬
3. **Teaching Documentation**: ë‹¨ìˆœ ì„¤ëª…ì´ ì•„ë‹Œ ì´í•´ë¥¼ ë•ëŠ” ë¬¸ì„œ
4. **Intent-Based Testing**: Coverage ìˆ«ìê°€ ì•„ë‹Œ ì˜ë„ ê²€ì¦ ì¤‘ì‹¬
5. **Prose-Like Code**: ì½”ë“œ ìì²´ê°€ ë¬¸ì„œê°€ ë˜ë„ë¡ ì‘ì„±

## Design Principles (ì„¤ê³„ ì§€ì¹¨)

**Phase ì§„í–‰ ì›ì¹™:**
- **Sequential Execution**: implementation â†’ testing â†’ documentation ìˆœì„œ ì—„ìˆ˜
- **Quality Gates**: ê° ë‹¨ê³„ë§ˆë‹¤ í’ˆì§ˆ ê²€ì¦ í•„ìˆ˜
- **Context-Aware Retry**: ì‹¤íŒ¨ ì‹œ ë§¥ë½ì„ ê³ ë ¤í•œ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- **Evidence-Based Decision**: JSON ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

**í’ˆì§ˆ ê¸°ì¤€ (Zero Tolerance):**
- Syntax Errors: 0
- Type Errors: 0  
- Linting Violations: 0
- Security Issues: 0
- Test Coverage: â‰¥ 95%
- Documentation: ì™„ì „ì„± 100%

## ğŸš€ Quality-Driven Multi-Agent Workflow

This command orchestrates a complete development pipeline with quality gates ensuring all deliverables meet SPARK standards before progressing.

### Workflow Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Implementer-Sparkâ”‚ â†â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
         â†“                â”‚ (Quality retry)
    Quality Gates â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ (Passed)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tester-Spark    â”‚ â†â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
         â†“                â”‚ (Coverage retry)
    Test Validation â”€â”€â”€â”€â”€â”€â”˜
         â†“ (95%+ achieved)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Documenter-Spark â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    âœ… Completion Report
```

## ğŸ“ 2í˜¸ Execution Protocol (ì •í™•í•œ ì‹¤í–‰ ì§€ì¹¨)

### **WHEN RECEIVING /spark-implement COMMAND:**

**PHASE 1: Implementation**
```bash
1. Task("implementer-spark", user_request)
2. Wait for completion
3. Check JSON: ~/.claude/workflows/current_task.json
   âœ… PASS CONDITIONS:
   - state.status == "completed"
   - quality.violations_total == 0  
   - quality.can_proceed == true
   - len(output.files.created) > 0 OR len(output.files.modified) > 0
   
   âŒ FAIL â†’ Retry: Task("implementer-spark", "Fix violations: [list specific quality issues]")
   Maximum 3 retries, then abort with error report.
```

**PHASE 2: Testing**
```bash
4. Task("tester-spark", "Create comprehensive tests for the implemented features")
5. Wait for completion  
6. Check JSON: ~/.claude/workflows/current_task.json
   âœ… PASS CONDITIONS:
   - state.status == "completed"
   - quality.step_6_testing.coverage >= 95
   - output.tests.unit > 0
   - quality.can_proceed == true
   
   âŒ FAIL â†’ Retry: Task("tester-spark", "Improve coverage to 95%+ and add missing tests")
   Maximum 2 retries, then abort with coverage report.
```

**PHASE 3: Documentation**
```bash
7. Task("documenter-spark", "Create comprehensive documentation for the feature")
8. Wait for completion
9. Check JSON: ~/.claude/workflows/current_task.json
   âœ… PASS CONDITIONS:
   - state.status == "completed"
   - output.docs.readme == true
   - output.docs.api == true (if API endpoints were created)
   - quality.step_7_documentation.docstrings == 0 (violations)
   
   âŒ FAIL â†’ Retry: Task("documenter-spark", "Complete missing documentation")
   Maximum 2 retries, then abort with documentation status.
```

**SUCCESS REPORT:**
```
âœ… Implementation Complete:
- Files: [list created/modified files]
- Tests: [coverage]% coverage, [count] test files
- Docs: README updated, API docs generated
- Quality: All gates passed (0 violations)
```

âš¡ **Core Principle**: 2í˜¸ëŠ” ê° ë‹¨ê³„ë§ˆë‹¤ JSON ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  ë‹¤ìŒ ì—ì´ì „íŠ¸ í˜¸ì¶œì„ ê²°ì •í•©ë‹ˆë‹¤

## ğŸ’¡ Quality Standards Summary

**Implementation**: Syntax(0), Types(0), Linting(0), Security(0), Docstrings(0)  
**Testing**: Coverage â‰¥95%, All tests pass, Edge cases covered  
**Documentation**: README updated, API docs complete, Examples provided

## ğŸš€ Usage Examples

```bash
/implement "Create secure user authentication with JWT tokens"
/implement "Build responsive dashboard with real-time data"
/implement "Implement data validation pipeline with error handling"
```

## ğŸ“Š SPARK Efficiency

- **Token Usage**: Lazy-loading architecture (only load required agents)
- **Quality Assurance**: 8 quality gates + retry system (max 3 attempts)
- **JSON Communication**: Unified current_task.json for all phases
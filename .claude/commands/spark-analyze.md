# /spark-analyze - SPARK Analysis Command

**Purpose**: Multi-dimensional code and system analysis with evidence-based investigation

## Execution Instructions

When this command is called, use the Task tool to launch the analyzer-spark agent:

```
Use the Task tool with subagent_type "analyzer-spark" to perform comprehensive analysis.
Pass the user's specific analysis request as the prompt parameter.
The analyzer-spark agent will conduct multi-perspective analysis and provide evidence-based insights.
```

## Usage Examples

```bash
/spark-analyze "performance bottlenecks in the authentication system"
/spark-analyze "security vulnerabilities in API endpoints"
/spark-analyze "code complexity and maintainability metrics"
/spark-analyze "dependency relationships and potential issues"
/spark-analyze "memory usage patterns in the data processing pipeline"
```

## Analysis Capabilities

- **Performance Analysis**: Bottlenecks, memory usage, optimization opportunities
- **Security Analysis**: Vulnerabilities, attack vectors, compliance issues  
- **Code Quality**: Complexity metrics, maintainability scores, technical debt
- **Architecture**: Structure analysis, coupling patterns, design issues
- **Dependencies**: Vulnerability scanning, usage optimization, conflict detection

## SPARK Intelligence Integration

- ğŸ­ **Code Analyst Persona**: Activates analytical thinking patterns
- ğŸ“Š **Evidence-Based**: All findings backed by data and metrics
- ğŸ” **Multi-Perspective**: Examines code from multiple angles
- ğŸš€ **88.4% Token Efficiency**: Focused analysis without token waste
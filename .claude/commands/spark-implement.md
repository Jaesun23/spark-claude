# /implement - SPARK Implementation Command

**Purpose**: Quality-driven implementation workflow with 2í˜¸'s intelligent orchestration and 88.4% token efficiency

## ğŸš€ Quality-Driven Multi-Agent Workflow

This command orchestrates a complete development pipeline with quality gates ensuring all deliverables meet SPARK standards before progressing.

### Workflow Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Implementer-Sparkâ”‚ â†â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
         â†“                â”‚ (Quality retry)
    Quality Gates â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ (Passed)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tester-Spark    â”‚ â†â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
         â†“                â”‚ (Coverage retry)
    Test Validation â”€â”€â”€â”€â”€â”€â”˜
         â†“ (95%+ achieved)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Documenter-Spark â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    âœ… Completion Report
```

## ğŸ“ Claude CODE Action Protocol

### **UPON RECEIVING /implement COMMAND:**
```python
# Claude CODE's ORCHESTRATION PROTOCOL (systematic 3-phase execution)
1. Task("implementer-spark", user_request)  # CALL IMMEDIATELY
2. Wait for SubagentStop hook signal
3. Claude CODE reviews implementation_result.json:
   - Check quality_metrics (linting, type checking)
   - Verify files_created and files_modified
   - Review next_steps and known_issues
4. DECISION:
   âœ… If satisfied â†’ Task("tester-spark", implementation_context)
   âŒ If issues found â†’ Task("implementer-spark", retry_with_feedback)

5. Wait for tester SubagentStop hook signal  
6. Claude CODE reviews test_result.json:
   - Check test coverage (target: 95%+)
   - Verify all tests passing
   - Review test quality metrics
7. DECISION:
   âœ… If satisfied â†’ Task("documenter-spark", context)
   âŒ If issues found â†’ Task("tester-spark", retry_with_feedback)

8. Wait for documenter SubagentStop hook signal
9. Claude CODE reviews documentation_result.json:
   - Verify README updates
   - Check API documentation
   - Confirm usage examples
10. FINAL DECISION:
    âœ… All phases complete â†’ Report success to user
    âŒ Issues found â†’ Task("documenter-spark", retry_with_feedback)
```

âš¡ **í•µì‹¬ ì›ì¹™**: Claude CODEê°€ ê° ë‹¨ê³„ë§ˆë‹¤ JSON ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  ë‹¤ìŒ ì—ì´ì „íŠ¸ í˜¸ì¶œ ê²°ì •

## ğŸ“ Orchestration Process

### Phase 1: Implementation (ìë™ ì‹¤í–‰)
I will immediately delegate to implementer-spark specialist:

1. **Task Assignment**: Request the implementer-spark specialist to implement the feature
2. **Quality Validation**: The SPARK quality gates hook automatically validates:
   - Syntax correctness (0 errors)
   - Type checking (MyPy 0 errors)
   - Linting compliance (Ruff 0 violations)
   - Security scanning (0 issues)
   - Documentation presence (docstrings required)
3. **Auto-Retry**: If quality gates fail, the specialist automatically retries (max 3 attempts)

**Quality Review Checklist:**
- âœ… Syntax validation (êµ¬ë¬¸ ì˜¤ë¥˜ 0ê°œ)
- âœ… Type checking (MyPy ì˜¤ë¥˜ 0ê°œ)  
- âœ… Linting (Ruff ìœ„ë°˜ 0ê°œ)
- âœ… Security scan (ë³´ì•ˆ ì´ìŠˆ 0ê°œ)
- âœ… Documentation (Docstring ì¡´ì¬)

**Phase 1 â†’ Phase 2 ìë™ ì§„í–‰:**
- âœ… ëª¨ë“  í’ˆì§ˆ ê²Œì´íŠ¸ í†µê³¼ (5/5) â†’ ìë™ìœ¼ë¡œ Phase 2 ì‹œì‘
- âœ… êµ¬í˜„ ì™„ë£Œ ê°ì§€ â†’ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¡œ ì „í™˜
- âœ… SubagentStop hook ì„±ê³µ â†’ ëŒ€ê¸° ì—†ì´ ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰

### Phase 2: Testing (ìë™ ì‹¤í–‰)
Once quality gates pass, I will immediately engage tester-spark specialist:

1. **Test Development**: Request comprehensive test creation with 95%+ coverage target
2. **Test Validation**: The test runner hook automatically verifies:
   - All tests passing (0 failures)
   - Coverage â‰¥ 95% (target achievement)
   - Edge cases covered (boundary testing)
   - Integration tests exist (system testing)
3. **Coverage Retry**: If coverage is below 95%, the specialist enhances tests (max 2 attempts)

**Test Quality Review:**
- âœ… All tests passing (ì‹¤íŒ¨ 0ê°œ)
- âœ… Coverage â‰¥ 95% (ëª©í‘œ ë‹¬ì„±)
- âœ… Edge cases covered (ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸)
- âœ… Integration tests exist (í†µí•© í…ŒìŠ¤íŠ¸)

**Phase 2 â†’ Phase 3 ìë™ ì§„í–‰:**
- âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (0 failures) â†’ ìë™ìœ¼ë¡œ Phase 3 ì‹œì‘
- âœ… ì»¤ë²„ë¦¬ì§€ 95% ë‹¬ì„± â†’ ì¦‰ì‹œ ë¬¸ì„œí™” ë‹¨ê³„ë¡œ ì „í™˜
- âœ… í…ŒìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ â†’ ëŒ€ê¸° ì—†ì´ ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰
- âœ… Hook ê²€ì¦ í†µê³¼ â†’ ìë™ ì§„í–‰ ì‹ í˜¸

### Phase 3: Documentation (ìë™ ì‹¤í–‰)
Once 95%+ coverage is achieved, I will immediately activate documenter-spark specialist:

1. **Documentation Creation**: Request comprehensive documentation including:
   - README updates with new features
   - API documentation for new endpoints
   - Usage examples and code samples
   - Inline docstrings for all functions
2. **Final Report**: Generate completion report with all deliverables

**Phase 3 ì™„ë£Œ ì¡°ê±´:**
- README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ
- API ë¬¸ì„œí™” ì™„ë£Œ (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
- ì‚¬ìš© ì˜ˆì œ ì¶”ê°€
- ëª¨ë“  í•¨ìˆ˜/í´ë˜ìŠ¤ì— docstring ì¡´ì¬
- ìµœì¢… êµ¬í˜„ ë³´ê³ ì„œ ì‘ì„±

## ğŸ’¡ í’ˆì§ˆ ê¸°ì¤€

### Implementation Quality (Phase 1)
- **í•„ìˆ˜ í†µê³¼ í•­ëª©**: Syntax (0), MyPy (0), Ruff (0), Security (0), Docstrings (0)

### Testing Quality (Phase 2) 
- **í•„ìˆ˜ ë‹¬ì„±**: Coverage â‰¥95%, Test failures (0), Edge cases covered

### Documentation Quality (Phase 3)
- **í•„ìˆ˜ í¬í•¨**: README updates, API docs, Usage examples, Inline docstrings

## ğŸš€ ì‚¬ìš© ì˜ˆì‹œ

```bash
/implement "Create secure user authentication with JWT tokens"
/implement "Build responsive dashboard with real-time data"
/implement "Implement data validation pipeline with error handling"
```

## ğŸ“Š SPARK íš¨ìœ¨ì„±

- **SuperClaude**: 44,000 tokens (all agents loaded)
- **SPARK**: 5,100 tokens average (88.4% reduction)
- **Cost Savings**: $0.78 per request
- **Quality Assurance**: 10 quality gates + automatic retry system
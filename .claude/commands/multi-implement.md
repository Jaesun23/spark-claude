# /multi-implement - SPARK Parallel Multi-Team Implementation

**Purpose**: Execute multiple implementation tasks in parallel using up to 4 teams with JSON context relay

## ü§ñ AVAILABLE TEAM AGENTS

**THESE ARE THE ONLY AGENTS FOR MULTI-IMPLEMENT:**
```
Team 1: team1-implementer-spark, team1-tester-spark, team1-documenter-spark
Team 2: team2-implementer-spark, team2-tester-spark, team2-documenter-spark
Team 3: team3-implementer-spark, team3-tester-spark, team3-documenter-spark
Team 4: team4-implementer-spark, team4-tester-spark, team4-documenter-spark
```
**DO NOT USE:** `implementer-spark`, `tester-spark`, `documenter-spark` (these are for single tasks)

## üö® CRITICAL: ONE MESSAGE WITH MULTIPLE TOOL CALLS üö®

### **THE GOLDEN RULE FOR PARALLEL EXECUTION:**
```
YOU MUST USE A SINGLE MESSAGE WITH MULTIPLE TASK TOOL CALLS!
DO NOT SEND SEPARATE MESSAGES FOR EACH TASK!
```

## ‚ö†Ô∏è PRE-EXECUTION CHECKLIST (MUST READ!)

Before executing /multi-implement, verify:
- [ ] ‚úÖ Using `team1-implementer-spark`, NOT `implementer-spark`
- [ ] ‚úÖ Using `team2-implementer-spark`, NOT `implementer-spark`  
- [ ] ‚úÖ Using `team3-implementer-spark`, NOT `implementer-spark`
- [ ] ‚úÖ Using `team4-implementer-spark`, NOT `implementer-spark`
- [ ] ‚úÖ NO "Team1:" prefix in task description (agent knows its team)
- [ ] ‚úÖ All 4 Task calls in ONE message
- [ ] ‚úÖ Team JSON files created first

## ‚ö° IMMEDIATE EXECUTION PROTOCOL

### **AS SOON AS YOU RECEIVE /multi-implement:**

```python
# ‚úÖ CORRECT - ALL IN ONE MESSAGE WITH TEAM-SPECIFIC AGENTS:
[Single Message]
‚îú‚îÄ‚îÄ Task("team1-implementer-spark", "{task1}")  # Uses team1_current_task.json
‚îú‚îÄ‚îÄ Task("team2-implementer-spark", "{task2}")  # Uses team2_current_task.json
‚îú‚îÄ‚îÄ Task("team3-implementer-spark", "{task3}")  # Uses team3_current_task.json
‚îî‚îÄ‚îÄ Task("team4-implementer-spark", "{task4}")  # Uses team4_current_task.json
[Wait for all to complete]

# ‚ùå WRONG #1 - USING GENERIC AGENT:
Task("implementer-spark", "Team1: ...")  # NO! Use team1-implementer-spark!
Task("implementer-spark", "Team2: ...")  # NO! Use team2-implementer-spark!

# ‚ùå WRONG #2 - SEQUENTIAL MESSAGES:
Message 1: Task("team1-implementer-spark", ...)
Message 2: Task("team2-implementer-spark", ...)  # NO! This waits for Team1!
```

### **EXECUTION STEPS:**
1. **PREPARE**: Create all team JSON files (team1_current_task.json, etc.)
2. **LAUNCH ALL AT ONCE**: Single message with 4 Task tool calls
3. **WAIT**: For all 4 teams to complete
4. **TEST ALL AT ONCE**: Single message with 4 tester Task calls
5. **REPORT**: Consolidate results

‚ö†Ô∏è **REMEMBER**: If you send Task calls in separate messages, they run SEQUENTIALLY, not in PARALLEL!

## üéØ COMMON MISTAKES TO AVOID

### ‚ùå Mistake 1: Using generic implementer-spark
```python
# WRONG - This breaks parallelism!
Task("implementer-spark", "Team 1: Implement API")
Task("implementer-spark", "Team 2: Implement Database")
```

### ‚ùå Mistake 2: Adding team prefix to task
```python
# WRONG - Agent already knows its team!
Task("team1-implementer-spark", "Team 1: Implement API")
# CORRECT - No prefix needed
Task("team1-implementer-spark", "Implement API")
```

### ‚ùå Mistake 3: Sequential messages
```python
# WRONG - Waits for each to finish!
Message 1: Task("team1-implementer-spark", ...)
[Wait for result]
Message 2: Task("team2-implementer-spark", ...)
```

## üìù Orchestration Process

### Phase 0: Task Allocation
Analyze tasks and allocate to teams:
1. Parse task IDs from command
2. Team JSON files will be auto-generated by StateManager:
   ```python
   # StateManager automatically creates team#_current_task.json files
   # when write_team_state(team_id, task_data) is called
   # Uses hardcoded _default_state() structure with team_id added
   ```
3. Identify shared resources needing locks

### Phase 1: Parallel Implementation
Call all assigned teams SIMULTANEOUSLY (not sequentially):
```
# ALL FOUR CALLS AT ONCE - NO WAITING BETWEEN!
Task("team1-implementer-spark", "{task1}")
Task("team2-implementer-spark", "{task2}")
Task("team3-implementer-spark", "{task3}")
Task("team4-implementer-spark", "{task4}")
```

Each team implementer:
- Automatically reads their team#_current_task.json file
- Implements only their assigned feature
- Updates their JSON file with 'implementation' section
- Runs self-validation before exit (recommended)
- Respects file locks for shared resources

### Phase 1.5: Claude CODE Implementation Review
After all implementations complete, Claude CODE reviews all team results:

```python
# Claude CODE reviews each team's results
1. Read team1_current_task.json (check 'implementation' section)
2. Read team2_current_task.json (check 'implementation' section)  
3. Read team3_current_task.json (check 'implementation' section)
4. Read team4_current_task.json (check 'implementation' section)

# Decision for each team:
‚úÖ If team results satisfactory ‚Üí Proceed to Phase 2
‚ùå If issues found ‚Üí Re-call that team's implementer
```

### Phase 2: Parallel Testing
After Claude CODE approves all implementations, call testers:
```
Task("team1-tester-spark", "Test Team 1 implementation")
Task("team2-tester-spark", "Test Team 2 implementation")
Task("team3-tester-spark", "Test Team 3 implementation")
Task("team4-tester-spark", "Test Team 4 implementation")
```

Each team tester:
- Automatically reads their team#_current_task.json
- Creates comprehensive tests (95% coverage target)
- Updates their JSON file with 'testing' section
- Runs self-validation before exit (recommended)

### Phase 2.5: Claude CODE Testing Review
After all testing complete, Claude CODE reviews all test results:

```python
# Claude CODE reviews each team's test results
1. Read team1_current_task.json (check 'testing' section)
2. Read team2_current_task.json (check 'testing' section)
3. Read team3_current_task.json (check 'testing' section)  
4. Read team4_current_task.json (check 'testing' section)

# Decision for each team:
‚úÖ If test coverage ‚â•95% and all tests pass ‚Üí Proceed to Phase 3
‚ùå If issues found ‚Üí Re-call that team's tester
```

### Phase 3: Parallel Documentation
After Claude CODE approves all testing, call documenters:
```
Task("team1-documenter-spark", "Document Team 1 work")
Task("team2-documenter-spark", "Document Team 2 work")
Task("team3-documenter-spark", "Document Team 3 work")
Task("team4-documenter-spark", "Document Team 4 work")
```

Each team documenter:
- Automatically reads their team#_current_task.json
- Documents implementation and test results
- Updates their JSON file with 'documentation' section
- Runs self-validation before exit (recommended)

### Phase 3.5: Claude CODE Documentation Review
After all documentation complete, Claude CODE reviews all documentation results:

```python
# Claude CODE reviews each team's documentation
1. Read team1_current_task.json (check 'documentation' section)
2. Read team2_current_task.json (check 'documentation' section)
3. Read team3_current_task.json (check 'documentation' section)
4. Read team4_current_task.json (check 'documentation' section)

# Decision for each team:
‚úÖ If documentation complete ‚Üí Mark team as finished
‚ùå If issues found ‚Üí Re-call that team's documenter
```

### Phase 4: Final Consolidation
After all teams pass all phases, Claude CODE provides final report:

```python
# Final multi-team implementation report
- Summary of all team implementations
- Consolidated quality metrics
- Integration points and dependencies
- Overall project completion status
```

## üí° Quality Criteria

Same as single implementation:
- MyPy strict: 0 errors
- Ruff: 0 violations
- Test coverage: ‚â•95%
- Security scan: 0 issues
- Documentation: Complete

## üîß JSON Context Structure

Each team's JSON file (team#_current_task.json) contains:
```json
{
  "team_id": "team1",
  "task_id": "TASK-API-01",
  "status": "implementing|testing|documenting|completed",
  "task_details": {
    "description": "Implement user authentication endpoint",
    "files_to_modify": ["api/auth.py"],
    "requirements": ["JWT support", "Refresh tokens"]
  },
  "implementation": {
    "agent": "team1-implementer-spark",
    "timestamp": "ISO-8601",
    "status": "completed",
    "files_created": ["api/auth.py"],
    "files_modified": ["main.py"],
    "quality_metrics": {
      "linting_passed": true,
      "type_checking_passed": true
    }
  },
  "testing": {
    "agent": "team1-tester-spark",
    "timestamp": "ISO-8601",
    "status": "completed",
    "test_files": ["tests/test_auth.py"],
    "coverage": 96,
    "all_tests_pass": true
  },
  "documentation": {
    "agent": "team1-documenter-spark",
    "timestamp": "ISO-8601",
    "status": "completed",
    "docs_created": ["docs/auth_api.md"],
    "readme_updated": true
  },
  "locks_held": ["constants.py"],
  "self_validated": true
}
```

## üîí File Lock Management

For shared resources (constants.py, types.py):
- Teams request locks through JSON
- Orchestrator manages lock allocation
- 30-second timeout prevents deadlocks

## üöÄ Usage Examples

```bash
# 2 tasks in parallel
/multi-implement "TASK-API-01" "TASK-UI-02"

# 4 tasks in parallel 
/multi-implement "TASK-API-01" "TASK-UI-02" "TASK-SEC-03" "TASK-DATA-04"

# With task descriptions
/multi-implement "Create user auth endpoint" "Build dashboard component" "Add security middleware" "Implement data pipeline"
```

## üìä Performance Benefits

- **2 tasks**: ~1.8x faster than sequential
- **3 tasks**: ~2.5x faster than sequential
- **4 tasks**: ~3.1x faster than sequential

## ‚ö†Ô∏è Limitations

- Maximum 4 teams (context window constraint)
- All teams wait for slowest to complete each phase
- Shared file modifications are serialized
- No direct agent-to-agent communication
# ğŸ­ SPARK v3.5 Agent Orchestration Architecture

## ğŸ¯ Core Philosophy
ì—ì´ì „íŠ¸ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ì •ë³´ íë¦„ê³¼ íš¨ìœ¨ì ì¸ ë³‘ë ¬ ì‘ì—…ì„ í†µí•œ ì™„ì „í•œ ì‘ì—… ìë™í™”

---

## ğŸ“Š Information Flow Architecture

### 1ï¸âƒ£ **ì •ë³´ ì£¼ì… ê²½ë¡œ (Input Channels)**

```mermaid
graph TD
    A[ì‚¬ìš©ì ìš”ì²­] --> B[Claude CODE ì§ì ‘ ì£¼ì…]
    A --> C[Hook ìë™ ì£¼ì…]
    B --> D[ì—ì´ì „íŠ¸]
    C --> D
    E[ìƒíƒœ íŒŒì¼] --> D
    F[ì‚¬ì „ ì½ê¸° ì§€ì‹œ] --> D
    G[MCP ì„œë²„] --> D
```

#### **ì£¼ì… ë°©ë²•ë³„ íŠ¹ì§•**

| ë°©ë²• | ìš©ë„ | ì˜ˆì‹œ | ì¥ì  |
|------|------|------|------|
| **Claude CODE í”„ë¡¬í”„íŠ¸** | í•µì‹¬ ìš”ì²­ ì „ë‹¬ | "implement auth system" | ì§ì ‘ì , ëª…í™• |
| **Hook ì»¨í…ìŠ¤íŠ¸** | ìë™ ë©”íƒ€ë°ì´í„° | í˜ë¥´ì†Œë‚˜, ë³µì¡ë„ | ìë™í™”, ì¼ê´€ì„± |
| **ìƒíƒœ íŒŒì¼** | êµ¬ì¡°í™”ëœ ì •ë³´ | current_task.json | ìƒì„¸ ì •ë³´, ì¬ì‚¬ìš© |
| **ì‚¬ì „ ì½ê¸°** | í•„ìˆ˜ ì»¨í…ìŠ¤íŠ¸ | "MUST READ requirements.md" | í‘œì¤€í™”, ê°•ì œì„± |
| **MCP ì„œë²„** | ì™¸ë¶€ ì •ë³´ | Context7 ë¬¸ì„œ, Memory | ìµœì‹  ì •ë³´, ì§€ì†ì„± |

### 2ï¸âƒ£ **ì •ë³´ ì¶œë ¥ ê²½ë¡œ (Output Channels)**

```mermaid
graph LR
    A[ì—ì´ì „íŠ¸] --> B[Claude CODE ë³´ê³ ]
    A --> C[ê²°ê³¼ íŒŒì¼]
    A --> D[TodoWrite]
    A --> E[ë‹¤ìŒ ì—ì´ì „íŠ¸]
    C --> E
```

#### **ì¶œë ¥ ë°©ë²•ë³„ í™œìš©**

| ë°©ë²• | ë‚´ìš© | í˜•ì‹ | í™œìš© |
|------|------|------|------|
| **í…ìŠ¤íŠ¸ ë³´ê³ ** | ì™„ë£Œ ë©”ì‹œì§€ | ìì—°ì–´ | ì‚¬ìš©ì í”¼ë“œë°± |
| **JSON íŒŒì¼** | êµ¬ì¡°í™” ê²°ê³¼ | implementation_result.json | ë‹¤ìŒ ì—ì´ì „íŠ¸ ì…ë ¥ |
| **TodoWrite** | ì§„í–‰ ìƒíƒœ | ì‘ì—… ëª©ë¡ | ì§„í–‰ë¥  ì¶”ì  |
| **HANDOFF.md** | ì¸ìˆ˜ì¸ê³„ | ë§ˆí¬ë‹¤ìš´ | ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬ |

---

## ğŸ”„ Context Relay System

### **ìˆœì°¨ ë¦´ë ˆì´ íŒ¨í„´**

```yaml
Step 1: Analyzer
  input: user_request + project_context
  output: analysis_result.json
  
Step 2: Implementer  
  input: analysis_result.json + requirements
  output: implementation_result.json
  
Step 3: Tester
  input: implementation_result.json
  output: test_result.json
  
Step 4: Documenter
  input: all_results.json
  output: documentation.md
```

### **íŒŒì¼ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ë¦´ë ˆì´**

```
.claude/workflows/
â”œâ”€â”€ current_task.json          # í˜„ì¬ ì‘ì—… ë©”íƒ€ë°ì´í„°
â”œâ”€â”€ analysis_result.json       # ë¶„ì„ ê²°ê³¼
â”œâ”€â”€ implementation_result.json  # êµ¬í˜„ ê²°ê³¼
â”œâ”€â”€ test_result.json           # í…ŒìŠ¤íŠ¸ ê²°ê³¼
â””â”€â”€ team1-4_result.json        # íŒ€ë³„ ê²°ê³¼
```

---

## ğŸš€ ë³‘ë ¬ ì‘ì—… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### **ë³‘ë ¬ ì‹¤í–‰ íŒ¨í„´**

```python
# Claude CODEì˜ ë³‘ë ¬ í˜¸ì¶œ
tasks = [
    Task("team1-implementer-spark", "implement auth module"),
    Task("team2-implementer-spark", "implement API endpoints"),
    Task("team3-implementer-spark", "implement database layer"),
    Task("team4-implementer-spark", "implement frontend")
]
# ë™ì‹œ ì‹¤í–‰ (Task Task Task Task â†’ ì‹œì‘!)
```

### **ì¶©ëŒ ë°©ì§€ ì „ëµ**

| ì „ëµ | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| **íŒŒì¼ ë¶„í• ** | íŒ€ë³„ ë‹¤ë¥¸ íŒŒì¼ ì‘ì—… | team1: auth.py, team2: api.py |
| **ê¸°ëŠ¥ ë¶„í• ** | ë„ë©”ì¸ë³„ ë¶„ë¦¬ | team1: backend, team2: frontend |
| **ë„¤ì„ìŠ¤í˜ì´ìŠ¤** | íŒ€ë³„ ë””ë ‰í† ë¦¬ | team1/*, team2/* |
| **JSON ê²©ë¦¬** | íŒ€ë³„ ìƒíƒœ íŒŒì¼ | team1_context.json |

---

## ğŸ“‹ ì—ì´ì „íŠ¸ ì •ì˜ íŒŒì¼ ê°œì„ 

### **í‘œì¤€ í…œí”Œë¦¿**

```markdown
---
name: implementer-spark
tools: Read, Write, Edit, Bash, TodoWrite
---

You are implementer-spark...

## ğŸ”¥ MANDATORY INITIALIZATION
Before ANY work, you MUST:
1. Read `.claude/workflows/current_task.json` for task context
2. Read `.claude/workflows/previous_result.json` if exists  
3. Check `docs/PROJECT_STANDARDS.md` for requirements

## ğŸ“¤ MANDATORY OUTPUT
After completing work, you MUST:
1. Write `.claude/workflows/implementation_result.json` with:
   - files_created: []
   - files_modified: []
   - key_decisions: {}
   - next_steps: []
2. Update TodoWrite with completion
3. Create `HANDOFF.md` if next agent needed

## ğŸ¯ Work Instructions
[ì‹¤ì œ ì‘ì—… ì§€ì‹œì‚¬í•­]
```

---

## ğŸ® Orchestration Levels

### **Level 1: ê²½ëŸ‰ (Simple)**
```yaml
ë³µì¡ë„: < 0.3
ë°©ë²•: Claude CODE í”„ë¡¬í”„íŠ¸ë§Œ
ì˜ˆì‹œ: "fix typo in README"
```

### **Level 2: í‘œì¤€ (Standard)**
```yaml
ë³µì¡ë„: 0.3-0.6
ë°©ë²•: í”„ë¡¬í”„íŠ¸ + ìƒíƒœ íŒŒì¼
ì˜ˆì‹œ: "add new API endpoint"
```

### **Level 3: ì‹¬í™” (Advanced)**
```yaml
ë³µì¡ë„: 0.6-0.8
ë°©ë²•: í”„ë¡¬í”„íŠ¸ + ìƒíƒœ + ì‚¬ì „ ì½ê¸°
ì˜ˆì‹œ: "refactor authentication system"
```

### **Level 4: ì™„ì „ (Complete)**
```yaml
ë³µì¡ë„: > 0.8
ë°©ë²•: ëª¨ë“  ì±„ë„ í™œìš© + ë³‘ë ¬ ì‹¤í–‰
ì˜ˆì‹œ: "implement entire microservice"
```

---

## ğŸ”§ Implementation Strategy

### **Claude CODEì˜ ì—­í•  (Orchestrator)**

```python
class Orchestrator:
    def execute(self, request):
        # 1. ë¶„ì„
        complexity = analyze_complexity(request)
        agents = select_agents(request)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = prepare_context(request, complexity)
        save_to_json(context, "current_task.json")
        
        # 3. ì‹¤í–‰ ì „ëµ
        if complexity < 0.7:
            # ìˆœì°¨ ì‹¤í–‰
            for agent in agents:
                result = Task(agent, context)
                context.update(result)
        else:
            # ë³‘ë ¬ ì‹¤í–‰
            results = parallel_execute(agents, context)
            merge_results(results)
        
        # 4. í’ˆì§ˆ ê²€ì¦
        validate_quality(results)
        
        # 5. í†µí•© ë³´ê³ 
        return generate_report(results)
```

### **Hookì˜ ë³´ì¡° ì—­í• **

```python
# UserPromptSubmit Hook
def enhance_prompt(input_data):
    prompt = input_data["prompt"]
    
    # ìë™ ë¶„ì„
    personas = detect_personas(prompt)
    complexity = calculate_complexity(prompt)
    
    # ì»¨í…ìŠ¤íŠ¸ ê°•í™”
    enhanced = f"""
    [SPARK Context]
    Complexity: {complexity}
    Personas: {personas}
    Quality Gates: Enabled
    
    {prompt}
    """
    
    return enhanced

# SubagentStop Hook  
def validate_quality(input_data):
    # í’ˆì§ˆ ê²€ì¦
    if not pass_quality_gates():
        return {"decision": "block", "reason": "Quality failed"}
    
    # ë‹¤ìŒ ì—ì´ì „íŠ¸ ì¤€ë¹„
    prepare_next_context()
    
    return {"continue": True}
```

---

## ğŸ“Š Complete Flow Example

### **ë³µì¡í•œ ê¸°ëŠ¥ êµ¬í˜„ ì‹œë‚˜ë¦¬ì˜¤**

```mermaid
sequenceDiagram
    participant U as User
    participant H as Hook
    participant O as Claude CODE
    participant A as Analyzer
    participant I as ImplementerÃ—4
    participant T as Tester
    participant D as Documenter
    
    U->>O: "implement chat system"
    O->>H: UserPromptSubmit
    H->>O: Enhanced context
    
    O->>A: Analyze requirements
    A->>O: analysis.json
    
    O->>I: Parallel implementation
    Note over I: Team1: Backend
    Note over I: Team2: Frontend  
    Note over I: Team3: Database
    Note over I: Team4: WebSocket
    
    I->>O: team1-4_result.json
    
    O->>T: Integration testing
    T->>H: SubagentStop
    H->>T: Quality validation
    T->>O: test_result.json
    
    O->>D: Documentation
    D->>O: docs.md
    
    O->>U: Complete report
```

---

## ğŸ¯ Best Practices

### **DO's âœ…**
1. **í•­ìƒ ìƒíƒœ íŒŒì¼ ì‚¬ìš©** - ì»¨í…ìŠ¤íŠ¸ ì§€ì†ì„± ë³´ì¥
2. **ëª…í™•í•œ ì¶œë ¥ ê·œê²©** - ë‹¤ìŒ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ í‘œì¤€í™”
3. **ë³‘ë ¬ ê°€ëŠ¥í•œ ì‘ì—… ì‹ë³„** - íš¨ìœ¨ì„± ê·¹ëŒ€í™”
4. **í’ˆì§ˆ ê²Œì´íŠ¸ í†µê³¼** - ê° ë‹¨ê³„ ê²€ì¦
5. **TodoWrite í™œìš©** - ì§„í–‰ ìƒí™© ì¶”ì 

### **DON'Ts âŒ**
1. **ê³¼ë„í•œ ë³‘ë ¬í™”** - ì¶©ëŒ ìœ„í—˜
2. **ì»¨í…ìŠ¤íŠ¸ ëˆ„ë½** - ì •ë³´ ë‹¨ì ˆ
3. **í‘œì¤€ ë¬´ì‹œ** - ì¼ê´€ì„± ê¹¨ì§
4. **ê²€ì¦ ìƒëµ** - í’ˆì§ˆ ì €í•˜
5. **ìƒíƒœ ë¯¸ê¸°ë¡** - ì¶”ì  ë¶ˆê°€

---

## ğŸš€ Advanced Patterns

### **Wave Pattern (ë³µì¡ë„ â‰¥0.7)**
```yaml
Wave 1: Discovery
  agents: [analyzer, loader]
  parallel: true
  
Wave 2: Implementation  
  agents: [team1-4-implementer]
  parallel: true
  
Wave 3: Integration
  agents: [tester, security]
  parallel: true
  
Wave 4: Quality
  agents: [improver, documenter]
  parallel: false
  
Wave 5: Deployment
  agents: [builder, deployer]
  parallel: false
```

### **Spawner Pattern (ì´ˆë³µì¡ ì‘ì—…)**
```python
# spawner-sparkê°€ ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
Task("spawner-spark", """
Orchestrate complete microservice implementation:
1. Architecture design
2. Parallel implementation (4 teams)
3. Integration and testing
4. Documentation and deployment
Coordinate all agents and manage dependencies.
""")
```

---

## ğŸ“š Reference Implementation

### **Current Task JSON Structure**
```json
{
  "task_id": "abc123",
  "prompt": "original request",
  "complexity": 0.75,
  "personas": ["Backend", "Frontend", "Security"],
  "agents": {
    "planned": ["analyzer", "implementer", "tester"],
    "completed": ["analyzer"],
    "in_progress": ["implementer"],
    "pending": ["tester"]
  },
  "context": {
    "project_type": "web_app",
    "framework": "React + FastAPI",
    "requirements": []
  },
  "results": {
    "analyzer": "analysis_result.json",
    "implementer": null,
    "tester": null
  }
}
```

### **Agent Result JSON Structure**
```json
{
  "agent": "implementer-spark",
  "task_id": "abc123",
  "timestamp": "2025-08-10T10:00:00Z",
  "status": "completed",
  "results": {
    "files_created": ["auth.py", "api.py"],
    "files_modified": ["main.py"],
    "tests_needed": ["test_auth.py"],
    "documentation_needed": ["API.md"]
  },
  "next_agent_context": {
    "focus_areas": ["security testing", "integration"],
    "critical_paths": ["login flow", "token refresh"]
  }
}
```

---

## ğŸ® Claude CODE Control Commands

### **Sequential Execution**
```python
# ìˆœì°¨ ì‹¤í–‰
result1 = Task("analyzer-spark", "analyze system")
# ê²°ê³¼ í™•ì¸ í›„
result2 = Task("implementer-spark", f"implement based on {result1}")
# ê²°ê³¼ í™•ì¸ í›„  
result3 = Task("tester-spark", f"test {result2}")
```

### **Parallel Execution**
```python
# ë³‘ë ¬ ì‹¤í–‰ (í•œ ë²ˆì— í˜¸ì¶œ)
Task("team1-implementer-spark", "backend")
Task("team2-implementer-spark", "frontend")
Task("team3-implementer-spark", "database")
Task("team4-implementer-spark", "api")
# ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
```

### **Hybrid Execution**
```python
# ë¶„ì„ ë¨¼ì €
Task("analyzer-spark", "analyze requirements")

# ë³‘ë ¬ êµ¬í˜„
Task("implementer-spark", "backend")
Task("designer-spark", "frontend")

# í†µí•© í…ŒìŠ¤íŠ¸
Task("tester-spark", "integration test")
```

---

## ğŸ“ˆ Performance Metrics

| Pattern | Token Usage | Time | Quality | Complexity |
|---------|-------------|------|---------|------------|
| **Sequential** | Low | Slow | High | Simple |
| **Parallel** | Medium | Fast | Medium | Complex |
| **Wave** | High | Medium | Very High | Very Complex |
| **Spawner** | Very High | Fast | Excellent | Ultra Complex |

---

*This architecture enables natural information flow between agents while maintaining efficiency and quality through systematic orchestration.*


# **요구사항 정의 프레임워크의 적용 및 확장: 'AI 외부 메모리' 시스템의 아키텍처 구체화 3단계 분석**

## **1\. 서론: 'AI 외부 메모리' 사례 연구의 정의 및 비교 분석**

### **1.1. 3단계 프레임워크의 핵심 가치 재조명**

소프트웨어 아키텍처 설계의 근본적인 도전 과제는 추상적인 비즈니스 목표를 구체적이고, 구현 가능하며, 방어 가능한 기술적 결정으로 변환하는 데 있습니다. 본 보고서는 이러한 변환 과정을 체계화하기 위해 이전에 제시된 3단계 요구사항 정의 프레임워크를 심층적으로 시연하는 것을 목적으로 합니다.

이 프레임워크는 다음과 같은 논리적 흐름을 따릅니다.

1. **1단계 (Why/What):** 비즈니스 목표, 사용자 페르소나, 핵심 기능 범위를 정의하는 표준 질문 단계.  
2. **2단계 (How Well):** 1단계의 추상적 요구를 구체적인 엔지니어링 속성(attributes) 및 비기능적 요구사항(NFRs)으로 변환하는 질문 단계.  
3. **3단계 (How):** 2단계에서 도출된 속성을 충족하는 기술 스택을 선정하고, 그 결정 과정을 아키텍처 결정 레코드(ADR)로 문서화하는 단계.

본 보고서의 핵심 가치는 이 프레임워크가 특정 도메인에 종속되지 않는 이식성(portability)과 적응성(adaptability)을 가지고 있음을 입증하는 데 있습니다. 이를 위해, 이전의 '문서 자동생성' 사례와는 질적으로 상이한 'AI 외부 메모리' 시스템을 새로운 사례 연구로 채택하여 프레임워크를 적용합니다.

### **1.2. 새로운 도전 과제: 'AI 외부 메모리' 시스템의 정의**

'AI 외부 메모리(AI External Memory)' 시스템은 단순한 데이터베이스나 키-값 저장소(key-value store)를 초월하는 개념입니다. 본 보고서에서 'AI 외부 메모리'는 AI 에이전트(또는 LLM)가 장기적인 맥락을 유지하고, 대화의 연속성을 보장하며, 방대한 외부 지식으로부터 관련 정보를 동적으로 검색하고, 새로운 정보를 지속적으로 학습(수집)할 수 있도록 지원하는 복합 시스템 아키텍처로 정의합니다.

기술적으로, 이는 RAG(Retrieval-Augmented Generation) 파이프라인의 핵심 구성 요소이며, 다음과 같은 기능적 블록을 반드시 포함합니다.

* **데이터 수집(Ingestion) 파이프라인:** 비정형 데이터(PDF,.txt, JSON 등)를 입력받아 청크(chunk)로 분할하고, 이를 벡터 임베딩(vector embedding)으로 변환합니다.  
* **벡터 저장소(Vector Storage):** 생성된 임베딩과 원본 텍스트 및 메타데이터를 저장하고, 고속의 시맨틱 검색(semantic search)을 지원합니다.  
* **검색 및 합성(Retrieval & Synthesis):** 사용자(또는 AI)의 질의를 임베딩하여 관련성 높은 정보를 검색하고, 이를 AI가 이해할 수 있는 형태로 가공하여 제공합니다.

### **1.3. 사례 연구 비교: '문서 자동생성' 대 'AI 외부 메모리'**

사용자의 요청( "서비스 성격과 대상이 완전히 다른 사례")을 충족시키기 위해, 두 시스템 간의 근본적인 차이점을 명확히 하는 것은 프레임워크 적용의 논리적 출발점입니다.

가장 핵심적인 차이는 \*\*'결정론적 시스템(Deterministic System)'\*\*과 \*\*'확률론적 시스템(Probabilistic System)'\*\*의 대비입니다.

'문서 자동생성' 시스템은 결정론적입니다. 입력 데이터(e.g., JSON)와 템플릿이 주어지면, 결과물(e.g., PDF)은 항상 100% 정확하고 예측 가능해야 합니다. 데이터가 누락되거나 잘못된 위치에 매핑되면, 이는 '치명적인 오류(Fatal Error)'입니다. 따라서 아키텍처는 '정확성(correctness)'과 '처리량(throughput)'에 최적화됩니다.

반면, 'AI 외부 메모리' 시스템은 본질적으로 확률론적입니다. "가장 관련성 높은 기억"을 찾는 것이 목표입니다. 검색 결과가 '틀린' 것이 아니라 '덜 유용'하거나 '관련성이 낮은' 것일 수 있습니다. 이는 시스템의 점진적 성능 저하(Graceful Degradation)를 의미합니다.

이러한 근본적인 차이는 아키텍처 설계의 무게 중심을 이동시킵니다. 결정론적 시스템의 1단계 질문이 "무엇을(What) 하는가?"에 집중된다면, 확률론적 시스템의 1단계 질문은 "얼마나 잘(How Well) 해야 하는가?"로 즉시 이동합니다. 즉, 'AI 외부 메모리' 시스템에서는 **비기능적 요구사항(NFRs)이 사실상의 핵심 기능적 요구사항**이 됩니다. '관련성', '지연 시간', '최신성'은 부가 기능이 아닌 시스템의 성패를 가르는 핵심 지표입니다.

이러한 차이점은 동일한 3단계 프레임워크가 왜 각기 다른 질문과 아키텍처 결정을 도출하는지 명확하게 설명해 줍니다.

**표 1\. 사례 연구 비교 분석**

| 특성 (Characteristic) | 사례 A: 문서 자동생성 (Case A: Document Auto-gen) | 사례 B: AI 외부 메모리 (Case B: AI External Memory) |
| :---- | :---- | :---- |
| **핵심 기능 (Core Function)** | 구조화된 데이터 매핑 및 템플릿 기반 렌더링 | 비구조화된 데이터의 시맨틱 검색 및 정보 합성 |
| **데이터 특성 (Data Nature)** | 구조화된 데이터 (JSON, XML), 정형 템플릿 | 비구조화된 텍스트, 벡터 임베딩, 복합 메타데이터 |
| **시스템 유형 (System Type)** | **결정론적 (Deterministic)** | **확률론적 (Probabilistic)** |
| **주요 실패 모드 (Failure Mode)** | 데이터 누락, 부정확한 매핑 (치명적 오류) | 관련성 낮은 정보 검색 (점진적 성능 저하) |
| **핵심 비기능적 요구사항 (Key NFR)** | 100% 정확성 (Correctness), 처리량 (Throughput) | **관련성 (Relevance)**, **지연 시간 (Latency)**, **최신성 (Freshness)** |

## **2\. 1단계: 'AI 외부 메모리'의 핵심 요구사항 정의 질문들**

이 단계의 질문들은 Google의 "How/Who/What"이나 Amazon의 "Working Backwards" 접근법과 맥을 같이하지만, 'AI 외부 메모리'라는 확률론적 시스템의 고유한 특성(데이터 의존성, NFR의 중요성)을 반영하여 변형 및 확장되었습니다.

### **2.1. 비즈니스 및 사용자 목표 질문 (The "Why" and "Who")**

**Q1: 이 'AI 메모리'의 궁극적인 비즈니스 가치(Business Value)는 무엇인가?**

* **분석:** 이 질문은 아키텍처의 최우선 순위를 결정합니다.  
  * (a) **내부 직원용 지식 관리 시스템 (비용 절감):** 아키텍처는 '검색 관련성'과 '보안(내부 접근 제어)'에 최적화됩니다. 확장성 요구는 비교적 낮을 수 있습니다.  
  * (b) **고객 대상 챗봇 (CSAT 향상):** 아키텍처는 '낮은 지연 시간(p99 Latency)'과 '대규모 동시 사용자(Concurrency)'를 처리하기 위한 '수평적 확장성(Horizontal Scalability)'에 최적화되어야 합니다.  
  * (c) **개발자용 API (신규 수익원):** 아키텍처는 '엄격한 데이터 격리(Multi-tenancy)', '사용량 기반 과금(Metering)', '안정적인 API 게이트웨이'에 최적화됩니다.  
  * 이 사례 연구에서는 (c) '개발자용 API'를 가정하여, 가장 복잡하고 엄격한 아키텍처 요구사항(특히 Q8)을 도출합니다.

**Q2: 메모리의 주 사용자는 누구인가(The "Who")? (a) 최종 사용자(Human-in-the-loop), (b) AI 에이전트(Autonomous agent), (c) 개발자(API consumer)인가?**

* **분석:** 이 질문은 전통적인 시스템 설계에서는 간과될 수 있지만, AI 시스템에서는 치명적인 아키텍처 분기점을 만듭니다. 사용자가 '인간'이 아닌 'AI 에이전트'일 경우, 시스템 요구사항의 패러다임이 전환됩니다.  
* 인간 사용자는 검색 결과의 '출처(source)'를 보고 스스로 신뢰도를 판단합니다. 하지만 AI 에이전트가 사용자인 경우, AI는 스스로 '메타인지(metacognition)'를 수행할 수 있어야 합니다. 즉, AI는 자신이 검색한 '기억'의 신뢰도를 판단할 근거를 시스템으로부터 제공받아야 합니다.  
* 이러한 논리적 추론은 "이 정보를 언제, 어디서, 누구로부터 얻었는가?"라는 \*\*정보의 출처(Provenance)\*\*와 "이 정보가 질의와 얼마나 일치하는가?"라는 \*\*신뢰도 점수(Confidence Score)\*\*를 API가 반환해야 한다는, 1단계의 핵심 기능 요구사항을 도출합니다. 이는 2단계에서 '메타데이터 저장 및 검색'이라는 구체적인 속성으로 변환됩니다.

### **2.2. 기능적 범위 질문 (The "What")**

**Q3: 어떤 유형(Types)의 정보를 "기억"해야 하는가? (a) 대화 로그(JSON), (b) 사용자 프로필(Structured), (c) 외부 문서(PDF,.txt), (d) 이미지/오디오(Multimodal)인가?**

* **분석:** 이 질문은 데이터 수집(Ingestion) 파이프라인의 복잡도를 결정합니다.  
  * (a), (b)는 비교적 간단한 임베딩 파이프라인을 요구합니다.  
  * (c) 'PDF,.txt'가 포함되는 순간, 문서를 의미 있는 단위로 분할하는 '청킹(Chunking)' 전략이 필요하며, 이는 검색 관련성(Q6)에 직접적인 영향을 미칩니다.  
  * (d) '멀티모달'이 요구되면, 텍스트 임베딩 모델(e.g., Ada-002)과 이미지 임베딩 모델(e.g., CLIP)을 모두 처리하고 저장할 수 있는, 즉 '멀티모달 임베딩 지원'이라는 2단계 속성이 필요하게 됩니다.

**Q4: 정보는 얼마나 오랫동안(Duration) 기억되어야 하는가? '망각(Forgetting)' 메커니즘이 필요한가?**

* **분석:** 이 질문은 단순한 디스크 용량(storage) 문제가 아닙니다. '망각'은 두 가지 핵심적인 비즈니스 요구사항과 연결됩니다.  
  * (a) **법적 요구사항 준수:** GDPR, CCPA 등에서 요구하는 '잊힐 권리(Right to be forgotten)'를 충족하기 위해, 특정 사용자(또는 테넌트)의 데이터를 즉시 영구 삭제하는 기능이 필수적입니다.  
  * (b) **관련성 유지 (Noise Reduction):** 너무 오래된 정보(e.g., 5년 전 뉴스)는 현재의 질의에 대해 '노이즈(noise)'로 작용하여 오히려 관련성(Q6)을 떨어뜨릴 수 있습니다.  
  * 따라서 '망각'은 (a) '즉시 삭제(Hard Delete)'와 (b) '관련성 점수 하락 또는 TTL(Time-to-Live) 적용(Soft Delete)'이라는 두 가지 구체적인 2단계 속성으로 분화됩니다.

**Q5: 정보의 '최신성(Freshness)' 요구사항은 무엇인가? 정보가 입력된 후 검색 가능해지기까지 허용되는 시간(Time-to-Ingest)은 얼마인가?**

* **분석:** 이 질문은 수집 아키텍처의 동기/비동기 여부를 결정짓는 핵심 변수입니다.  
  * (a) **즉시 (수 초 이내):** 실시간 대화가 바로 다음 검색에 반영되어야 하는 경우.  
  * (b) **1시간 이내:** 뉴스 기사나 블로그 포스트가 수집되는 경우.  
  * (c) **1일 (야간 배치):** 전날의 로그를 분석하는 경우.  
  * 만약 (a) '즉시'가 요구되면서 동시에 Q7의 '낮은 검색 지연 시간'이 요구된다면, 이는 3단계에서 '동기식(Synchronous)' API 아키텍처가 불가능함을 시사합니다.

### **2.3. 비기능적 제약조건 질문 (The "How Well")**

(서문: 1.3에서 분석했듯이, 'AI 외부 메모리' 시스템에서 "How Well"은 시스템의 성패를 가르는 가장 중요한 질문들입니다.)

**Q6: "관련성(Relevance)"을 어떻게 정의하고 측정할 것인가?**

* **분석:** 이것이 전체 시스템 아키텍처의 *최우선* 질문이자 가장 어려운 질문입니다. '관련성'이라는 추상적인 목표는 구체적인 측정 지표로 정의되어야 합니다.  
  * (a) **순수한 시맨틱 유사성 (Cosine Similarity):** 가장 기본적인 정의이지만, 키워드 검색(e.g., "Project\_SK-3000")을 놓칠 수 있습니다.  
  * (b) **사용자 피드백 (Up/Down-voting):** 사용자가 검색 결과를 평가(e.g., "Thumbs Up/Down")하고, 이 피드백이 다음 검색에 반영(Re-ranking)되어야 합니다.  
  * (c) **최종 태스크 성공률 (Task Completion Rate):** AI 에이전트가 이 메모리를 사용하여 특정 작업을 성공적으로 완료하는 비율로 측정합니다.  
  * 만약 (a)만 요구된다면 단순 벡터 검색으로 충분하지만, (b)나 (c)가 요구된다면, 아키텍처는 '피드백 루프(Feedback Loop)'와 '재순위(Re-ranking) 모델'을 포함하는 2단계 속성을 반드시 가져야 합니다.

**Q7: 검색(Retrieval) 지연 시간(Latency)의 p99 목표는 무엇인가?**

* **분석:** 'p99' (99th percentile)를 목표로 설정하는 것이 중요합니다. 이는 평균(average) 응답 시간이 아닌, 대부분의 사용자(99%)가 경험하는 최악의 응답 시간을 기준으로 삼겠다는 의미입니다.  
  * (a) **대화형 AI (실시간 응답):** 사용자가 응답을 기다리는 것을 인지하지 못해야 하므로, p99가 500ms 미만이어야 할 수 있습니다.  
  * (b) **비동기 분석 작업:** p99가 5초 미만이어도 허용될 수 있습니다.  
  * (a) 'p99 \< 500ms'라는 요구사항은 2단계에서 '인메모리(In-memory) 인덱스', '고효율 캐싱 전략', '지리적으로 분산된 읽기 복제본(Read Replicas)'과 같은 매우 비싼(?) 엔지니어링 속성을 강제합니다.

**Q8: 데이터 격리(Isolation) 및 보안 요구사항은 무엇인가?**

* **분석:** (Q1에서 '개발자용 API'를 가정했으므로) 이 질문은 아키텍처의 근간을 결정합니다. 다중 테넌트(Multi-tenant) SaaS를 구축할 때, 테넌트 A의 데이터가 테넌트 B에게 절대 노출되어서는 안 됩니다.  
  * (a) **테넌트 간 완벽한 격리:** 모든 API 요청은 tenant\_id를 기반으로 데이터를 필터링해야 합니다.  
  * (b) **사용자별 개인화 메모리:** tenant\_id 내에서도 user\_id별로 메모리가 격리되어야 할 수 있습니다.  
  * 이 요구사항은 2단계에서 "단순한 벡터 검색"이 아닌, "**메타데이터(tenant\_id) 기반의 필터링을 지원하는 벡터 검색**"이라는 매우 구체적인 속성으로 변환됩니다.

## **3\. 2단계: 요구사항에서 구현 속성(Attributes)으로의 변환 질문들**

이 단계는 1단계의 추상적인 '비즈니스 언어'(e.g., "즉각적인 최신성", "높은 관련성")를 3단계에서 기술로 구현 가능한 구체적이고 테스트 가능한 '엔지니어링 속성'으로 변환하는 핵심 브릿지입니다.

### **3.1. 데이터 수집(Ingestion) 속성 질문**

* **From (Stage 1):** Q3 ("다양한 정보 유형"), Q5 ("즉각적인 최신성"), Q7 ("낮은 검색 API 지연 시간")  
* **To (Stage 2 Question):** "1단계의 Q5('즉각적 수집')와 Q7('낮은 API 지연 시간')은 서로 상충하지 않는가? 이는 '실시간(Real-time), 비동기식(Asynchronous), 멀티모달(Multi-modal) 임베딩 파이프라인'이라는 속성을 요구하는가?"  
* **분석:**  
  * 만약 데이터 수집 API가 동기식(Synchronous)으로 작동한다고 가정해 봅시다. API 요청 시 \-\> (1)데이터 청킹 \-\> (2)임베딩 모델 호출 (수백 ms) \-\> (3)벡터 DB 저장 (수십 ms) \-\> (4)200 OK 응답.  
  * 이 시나리오는 임베딩 모델 호출(외부 네트워크 I/O) 시간 때문에 Q7의 '낮은 API 지연 시간' 목표(e.g., \< 50ms)를 절대 만족시킬 수 없습니다.  
  * 따라서, Q5와 Q7의 상충되는 요구를 해결하기 위한 유일한 아키텍처 속성은 \*\*'비동기식(Asynchronous) 수집'\*\*입니다. API는 데이터를 즉시 메시지 큐(e.g., Kafka)에 적재하고 202 Accepted를 반환하며, 실제 임베딩과 저장은 백그라운드 워커가 처리해야 합니다.  
  * 이 결정은 '즉각적인 최신성'(Q5)을 포기하고 \*\*'최종 일관성(Eventual Consistency)'\*\*이라는 속성을 수용하는 트레이드오프를 발생시킵니다. (ADR 2에서 상세히 다룸)  
  * 또한 Q3("다양한 정보 유형")은 '멀티모달' 또는 '다중 모델(e.g., 텍스트용, 이미지용)'을 처리할 수 있는 파이프라인 속성을 요구합니다.  
  * **도출된 속성:** '비동기식 수집', '최종 일관성(Eventual Consistency)', '멀티모달 임베딩 지원'.

### **3.2. 데이터 저장(Storage) 속성 질문**

* **From (Stage 1):** Q6 ("관련성"), Q8 ("데이터 격리"), Q4 ("망각")  
* **To (Stage 2 Question):** "이는 '메타데이터 필터링(Metadata Filtering)을 지원하는 벡터 인덱스' 속성을 필요로 하는가?"  
* **분석:**  
  * 이것은 'AI 외부 메모리' 아키텍처의 핵심 기술적 변환입니다.  
  * Q6("관련성") \-\> '벡터 인덱스' (시맨틱 검색) 속성.  
  * Q8("데이터 격리") \-\> 'tenant\_id 기준 필터링' 속성.  
  * Q4("망각") \-\> 'timestamp 기준 TTL 또는 is\_deleted 플래그 필터링' 속성.  
  * 이 세 가지 요구사항이 결합되면, 시스템은 "X 테넌트의(Q8), 지난 24시간 이내의(Q4), PDF 문서(Q3) 중에서 'AI'와 관련된(Q6)" 검색을 수행해야 합니다.  
  * 이는 단순한 벡터 검색(k-NN, Nearest Neighbor)이 아니라 \*\*'필터링된 벡터 검색(Filtered k-NN)'\*\*입니다.  
  * 이때 중대한 기술적 함정이 발생합니다. 대부분의 벡터 인덱스(e.g., HNSW)는 필터링 없는 순수 k-NN에 최적화되어 있습니다. 필터링을 적용하는 방식은 (a) 검색 후 필터링(Post-filtering)과 (b) 검색 전 필터링(Pre-filtering)이 있습니다.  
  * (a) **검색 후 필터링:** 먼저 100개의 벡터를 검색한 뒤, 이 100개가 메타데이터 필터(e.g., tenant\_id \= 'A')와 일치하는지 확인합니다. 이 방식은 필터링 후 결과가 0개일 수 있으며(매우 부정확), 검색 공간이 줄어들지 않아 매우 비효율적입니다.  
  * (b) **검색 전 필터링:** 인덱스 구조 자체가 메타데이터 필터링을 지원하여, 처음부터 tenant\_id \= 'A'인 벡터들 내에서만 k-NN 검색을 수행합니다. 이는 훨씬 효율적이지만 모든 벡터 DB가 이를 고성능으로 지원하지 않습니다.  
  * 따라서 2단계에서 도출된 속성은 단순한 '벡터 인덱스'가 아니라, \*\*'고효율 메타데이터 사전 필터링(Pre-filtering)을 지원하는 벡터 인덱스'\*\*라는 매우 구체적이고 까다로운 속성으로 정의되어야 합니다. 이는 3단계의 기술 선택(Milvus vs. Pinecone vs. PGvector)을 결정짓는 핵심 요인이 됩니다.

### **3.3. 데이터 검색(Retrieval) 속성 질문**

* **From (Stage 1):** Q6 ("최고의 관련성"), Q2/Insight 2 ("출처 추적")  
* **To (Stage 2 Question):** "단순 시맨틱 검색만으로 1단계의 '관련성' 목표 달성이 불가능한가? '하이브리드 검색(Hybrid Search)' 및 '재순위(Re-ranking) 모델' 속성이 필수적인가?"  
* **분석:**  
  * 시맨틱 검색(벡터)은 '의미'("인공지능의 미래")는 잘 찾지만, '특정 키워드'("Project\_SK-3000")는 놓칠 수 있습니다. 반대로 전통적인 키워드 검색(e.g., BM25)은 '정확한 용어'는 잘 찾지만 '의미'는 모릅니다.  
  * 1단계의 '최고의 관련성'(Q6)을 달성하기 위해서는 이 둘의 장점을 결합해야 합니다.  
  * **도출된 속성 1:** '하이브리드 검색' (시맨틱 \+ 키워드 검색 결과의 결합).  
  * **도출된 속성 2:** 관련성을 극대화하기 위해, 하이브리드 검색으로 100개의 후보를 찾은 뒤, 더 정교하지만 느린(따라서 100개에만 적용 가능한) 모델을 사용하여 이 100개의 순서를 다시 정렬하는 **'2단계 재순위(Two-stage Re-ranking)'** 속성이 필수 속성으로 도출될 수 있습니다.  
* **To (Stage 2 Question):** "검색 API 응답은 '출처 메타데이터(Provenance Metadata)'를 포함하는 '투명한 응답(Transparent Response)' 속성을 가져야 하는가?"  
* **분석:**  
  * 1단계(Q2)의 'AI를 사용자로 간주'할 때 도출된 '출처 추적' 요구사항은, 여기서 구체적인 엔지니어링 속성으로 변환됩니다.  
  * API 응답은 단순히 검색된 텍스트뿐만 아니라, AI 에이전트(또는 인간)가 신뢰도를 판단할 수 있도록 {'source\_url': '...', 'created\_at': '...', 'confidence\_score': 0.92}와 같은 메타데이터를 포함해야 합니다.  
  * **도출된 속성:** '출처 메타데이터를 포함하는 투명한 API 응답'.

## **4\. 3단계: 기술 스택 선정 및 아키텍처 결정 레코드 (ADR) 작성**

2단계에서 정의된 구체적인 속성(Attributes)을 충족시키는 실제 기술 스택을 선택하고, 그 과정에서 발생한 트레이드오프를 ADR(Architecture Decision Record) 형식으로 명확히 기록합니다.

### **4.1. 기술 스택 후보군 분석 (AI 메모리 중심)**

* **데이터 수집 파이프라인 (속성: 비동기식, 실시간):**  
  * *후보:* Kafka, RabbitMQ, AWS Kinesis, Google Pub/Sub  
* **임베딩 모델 (속성: 멀티모달, 고관련성):**  
  * *후보:* OpenAI (Ada-002, text-embedding-3), Cohere (Embed v3), S-BERT (오픈소스)  
* **RAG 오케스트레이션 (속성: 복잡한 파이프라인 관리):**  
  * *후보:* LangChain, LlamaIndex, (또는 경량화를 위한 Custom Python/Go)  
* **벡터 데이터베이스 (속성: 고효율 메타데이터 사전 필터링, 확장성):**  
  * *후보:* Milvus, Pinecone, Weaviate, Qdrant, PGvector(PostgreSQL)

### **4.2. 상세 ADR 작성 예시 1: 벡터 저장소 기술 선택 (ADR Example 1: Vector Storage Selection)**

* **제목 (Title):** 벡터 저장소로 Milvus 채택  
* **배경 (Context):**  
  * 2단계 분석(3.2)을 통해, 아키텍처는 '수평적 확장성', '고효율 메타데이터 사전 필터링'(2단계의 핵심 속성), '실시간 수집 지원'이라는 핵심 속성을 반드시 충족해야 함이 식별되었습니다.  
  * 또한 1단계 Q1/Q8에서 '개발자용 API' 및 'SaaS'를 가정함에 따라, 벤더 종속성(vendor lock-in)을 회피하고 비용을 통제할 수 있는 '오픈소스'가 선호됩니다.  
  * 1단계의 Q8(데이터 격리) 요구는 'tenant\_id 필터링' 성능이 전체 시스템의 보안과 성능을 좌우하는 결정적 요인임을 의미합니다.  
* **결정 (Decision):**  
  * 오픈소스 벡터 데이터베이스인 **Milvus**를 Kubernetes(K8s) 클러스터에 자체 호스팅(self-hosting)하여 채택한다.  
* **고려된 대안 (Alternatives Considered):**  
  * *대안 1: Pinecone (SaaS):* '메타데이터 필터링' 성능은 매우 우수하며, K8s 운영 부담이 전혀 없습니다. 그러나 완전한 SaaS 솔루션으로 '벤더 종속성'이 발생하며, 1단계 Q1에서 고려한 '비용 효율성' 측면에서 대규모(수십억 벡터) 운영 시 자체 호스팅 대비 불리할 수 있습니다.  
  * *대안 2: PGvector (PostgreSQL Extension):* 기존 PostgreSQL에 벡터 검색 기능을 추가하는 방식입니다. '메타데이터'(일반 컬럼)와 '벡터'를 한곳에서 관리하여 아키텍처가 단순해지는 강력한 장점이 있습니다. 그러나, HNSW 인덱스의 '메타데이터 사전 필터링' 기능이 Milvus와 같은 전문 벡터 DB 대비 미흡하며, 1단계의 '수십억 개' 수준의 대규모 벡터 확장성(Q7)에 대한 검증이 상대적으로 부족합니다.  
  * *대안 3: ChromaDB (In-memory/lightweight):* 초기 개발(PoC) 및 소규모 애플리케이션에는 매우 빠르고 유용합니다. 그러나 2단계에서 요구된 '실시간 대규모 수집' 및 '수평적 확장성' 속성을 충족하지 못하여 프로덕션급 SaaS에는 부적합하다고 판단되었습니다.  
* **결과 (Consequences):**  
  * *장점:* 2단계에서 요구된 모든 핵심 속성(확장성, 고성능 필터링)을 충족하며 벤더 종속성을 피합니다. 데이터는 자체 인프라 내에서 완벽하게 통제됩니다.  
  * *단점 (Trade-off):* K8s 기반의 복잡한 분산 시스템(Milvus)을 자체 운영해야 하므로, \*\*운영 복잡성(Operational Complexity) 및 유지보수 비용(전문 인력)\*\*이 크게 증가합니다. 이는 '기술'이 아닌 '사람과 비용'의 트레이드오프입니다.

### **4.3. 상세 ADR 작성 예시 2: 데이터 수집 파이프라인 아키텍처 (ADR Example 2: Data Ingestion Pipeline Architecture)**

* **제목 (Title):** Kafka 기반 비동기식 이벤트 기반 수집 아키텍처 채택  
* **배경 (Context):**  
  * 1단계에서 '실시간 수집'(Q5)과 '낮은 API 응답 시간'(Q7과 연관됨)이 동시에 요구되었습니다.  
  * 2단계 분석(3.1) 결과, 이 두 요구사항은 동기식(Synchronous) API 처리 방식으로는 양립이 불가능하며, '비동기식 수집' 속성이 필수적임이 도출되었습니다.  
* **결정 (Decision):**  
  * 데이터 수집 API는 요청(e.g., PDF 업로드)을 즉시 **Kafka** 토픽에 적재하고 202 Accepted를 반환한다.  
  * 별도의 임베딩 워커(Embedding Workers)가 Kafka 토픽을 컨슘(consume)하여 청킹, 임베딩 모델 호출, Milvus 저장을 비동기적으로 처리한다.  
* **고려된 대안 (Alternatives Considered):**  
  * *대안 1: 동기식 API 처리 (Synchronous):* API 요청 시 임베딩과 Milvus 저장을 모두 완료하고 200 OK를 반환합니다.  
  * *분석:* 이 대안은 아키텍처가 단순하고 데이터 일관성(수집 즉시 검색 가능)이 보장됩니다. 그러나 임베딩 모델 호출(네트워크 I/O) 및 벡터 DB 쓰기 시간으로 인해 API 지연 시간이 수백 ms에서 수 초까지 증가할 수 있습니다. 이는 1단계의 '실시간 대화형 AI'(Q7) 요구사항을 만족시킬 수 없습니다. 즉, Q5('즉시')와 Q7('빠른 응답')의 요구사항이 정면으로 상충됩니다.  
* **결과 (Consequences):**  
  * *장점:* 수집 API의 응답 시간이 매우 짧게(e.g., \< 50ms) 유지됩니다. 수집 트래픽 폭증(burst traffic)이 발생하더라도 Kafka가 이를 버퍼(buffer) 역할을 하여 시스템 전체의 안정성(resilience)이 높습니다.  
  * *단점 (Trade-off):* \*\*최종 일관성(Eventual Consistency)\*\*이 발생합니다. 즉, 데이터가 수집된 시점(API가 202Accepted를 반환한 시점)과 해당 데이터가 검색 가능한 시점 사이에 수 초간의 지연(lag)이 필연적으로 발생합니다. 이는 1단계의 "즉각적 기억"(Q5) 요구사항을 100% 충족하지 못하며, 이 트레이드오프는 비즈니스(PM)의 명시적인 승인이 필요합니다.

### **4.4. 상세 ADR 작성 예시 3: 데이터 격리(테넌트) 구현 전략 (ADR Example 3: Data Isolation (Tenancy) Strategy)**

* **제목 (Title):** Milvus 컬렉션 내 메타데이터 필터링을 통한 논리적 테넌트 분리  
* **배경 (Context):**  
  * 1단계에서 '엄격한 테넌트 간 데이터 격리'(Q8)가 비즈니스 및 보안의 핵심 요구사항으로 정의되었습니다.  
  * 2단계(3.2)에서 이는 '고효율 tenant\_id 필터링' 속성으로 변환되었습니다.  
  * 이제 이 속성을 어떻게 물리/논리적으로 구현할지 결정해야 합니다.  
* **결정 (Decision):**  
  * 모든 테넌트의 데이터를 (물리적으로) 단일 Milvus 컬렉션(Collection)에 저장한다.  
  * 각 벡터 청크(chunk)의 메타데이터에 tenant\_id를 필수적으로 포함한다.  
  * 모든 검색/삭제 쿼리는 API 게이트웨이 또는 서비스 계층에서 \*\*tenant\_id 필터를 강제(enforce)\*\*한다. (즉, 논리적 분리)  
* **고려된 대안 (Alternatives Considered):**  
  * *대안 1: 테넌트별 별도 컬렉션(또는 DB) 생성 (Physical Separation):*  
  * *분석:* 이 대안은 완벽한 물리적 격리를 제공하여 보안성이 가장 높습니다. 한 테넌트의 데이터가 다른 테넌트로 유출될 가능성이 원천적으로 차단됩니다.  
  * *문제:* 1단계에서 '수천, 수만'의 테넌트(e.g., 사용자별 개인화 메모리)를 가정할 때, 수천 개의 Milvus 컬렉션을 생성/관리하는 것은 막대한 리소스(메모리 오버헤드)와 관리 복잡성을 초래합니다. 이는 2단계의 '효율적 확장성' 속성에 위배됩니다.  
* **결과 (Consequences):**  
  * *장점:* 비용 효율적입니다(리소스 공유). 수평적 확장성이 뛰어나며, 신규 테넌트 온보딩(새 tenant\_id 추가)이 즉각적입니다.  
  * *단점 (Trade-off):* **보안 위험이 인프라 계층에서 애플리케이션 로직 계층으로 이동합니다.** tenant\_id 필터링을 강제하는 애플리케이션 로직에 단 하나의 버그(bug)라도 존재할 경우(e.g., tenant\_id 누락 시 전체 검색), 심각한 데이터 유출 사고로 이어질 수 있습니다.  
  * *조치:* 따라서 이 결정을 채택하는 대가로, **엄격한 코드 리뷰, 다층적 권한 검증 로직, 필터링 누락을 검증하는 QA 테스트 케이스**가 필수적으로 요구됩니다.

## **5\. 결론: 프레임워크 적용을 통한 통찰 및 권고 사항**

### **5.1. 프레임워크의 적응성 및 유효성 검증**

본 보고서는 '문서 자동생성'(결정론적)과 'AI 외부 메모리'(확률론적)라는, 서비스의 성격과 대상이 판이하게 다른 두 도메인에 동일한 3단계(질문 \-\> 속성 \-\> 결정) 요구사항 정의 프레임워크가 성공적으로 적용됨을 입증했습니다.

이는 본 프레임워크가 특정 도메인이나 기술 스택에 종속되지 않고, 추상적인 비즈니스 요구를 구체적인 아키텍처 결정으로 변환하는 과정의 근본적인 논리 흐름을 따르고 있음을 시사합니다. 'AI 외부 메모리' 사례에서, 프레임워크는 확률론적 시스템의 고유한 복잡성(e.g., '관련성' 측정, '필터링된 검색')을 1단계와 2단계에서 효과적으로 식별하고, 3단계에서 이에 대한 명시적인 트레이드오프(e.g., '최종 일관성', '논리적 격리의 보안 위험')를 ADR로 문서화하도록 유도했습니다.

### **5.2. AI 시스템 아키텍처 설계를 위한 핵심 통찰**

프레임워크 적용 과정을 통해 AI 시스템 아키텍처 설계에 대한 다음과 같은 핵심적인 시사점을 도출할 수 있습니다.

1. NFRs가 아키텍처를 주도합니다 (NFRs Drive Architecture).  
   'AI 외부 메모리'(특히 RAG)와 같은 확률론적 시스템의 경우, '관련성'(Relevance), '지연 시간'(Latency), '최신성'(Freshness), '격리성'(Isolation)과 같은 비기능적 요구사항(NFRs)이 시스템의 성패를 좌우하는 사실상의 '핵심 기능'입니다. 3단계(기술 선택)는 결국 이 NFRs 간의 우선순위를 정하고 트레이드오프를 결정하는 과정입니다. (e.g., ADR 2: '최신성'을 일부 희생하고 '지연 시간'을 확보).  
2. 복합 요구사항의 함정을 주의해야 합니다 (Beware Combined Requirements).  
   개별적인 요구사항은 단순해 보일 수 있으나, 이들이 결합될 때 발생하는 기술적 난이도를 2단계에서 정확히 식별하는 것이 중요합니다. '필터링된 벡터 검색'(3.2) 사례가 이를 명확히 보여줍니다. '관련성 검색'(Q6)과 '데이터 격리'(Q8)라는 두 가지 요구사항이 결합되자, 이는 단순한 k-NN 문제가 아닌 '고효율 사전 필터링'이라는 훨씬 더 복잡한 기술적 속성을 요구하게 되었습니다.

### **5.3. 타 AI 시스템 적용을 위한 권고 사항**

향후 유사한 AI 시스템 아키텍처를 설계할 때, 본 프레임워크를 효과적으로 적용하기 위해 다음 사항을 권고합니다.

1. "How Well"을 먼저 정의하십시오.  
   AI 시스템 설계를 시작할 때, 1단계에서 "무엇을(What)"보다 "어떻게 측정할 것인가(How to Measure)"를 정의하는 데 더 많은 노력을 투입해야 합니다. "관련성을 어떻게 측정할 것인가?"(Q6)는 시스템의 평가 기준(Evaluation Metric)이자 가장 중요한 아키텍처 드라이버(Driver)입니다. 이 정의가 모호하면 2단계, 3단계 전체가 표류하게 됩니다.  
2. 트레이드오프를 명시적으로 문서화하십시오.  
   ADR 2(실시간성 vs. 최종 일관성), ADR 3(보안성 vs. 비용/확장성)에서 보듯이, 복잡한 시스템 아키텍처는 '완벽한' 해결책이 아닌 '최적의 트레이드오프'를 찾는 과정입니다. 이러한 트레이드오프를 ADR로 명확히 기록하고 비즈니스 이해관계자(PM, 보안팀 등)의 동의를 얻는 것이, 기술적 부채를 방지하고 방어 가능한 아키텍처를 구축하는 핵심입니다.

---

**표 2\. 3단계 프레임워크 적용 요약 (AI 외부 메모리)**

| 기능 영역 (Functional Area) | 1단계: 핵심 질문 (Stage 1: Key Question) | 2단계: 도출된 속성 (Stage 2: Derived Attribute) | 3단계: 아키텍처 결정 (Stage 3: Architectural Decision) |
| :---- | :---- | :---- | :---- |
| **데이터 수집 (Ingestion)** | Q5(실시간 수집)과 Q7(API 응답 시간)을 어떻게 양립시킬까? | '비동기식', '이벤트 기반 수집', '최종 일관성' | Kafka \+ 비동기 Embedding Workers (ADR 2\) |
| **데이터 저장 (Storage)** | Q6(관련성), Q8(격리성)을 대규모로 어떻게 보장할까? | '고효율 메타데이터 사전 필터링'을 지원하는 '수평적 확장 가능' 벡터 인덱스 | Milvus on Kubernetes (ADR 1\) |
| **데이터 격리 (Isolation)** | Q8(수천 개 테넌트)을 어떻게 효율적이고 엄격하게 격리할까? | '논리적 분리' (물리적 분리는 확장성 위배) | tenant\_id 메타데이터 필터링 강제 (ADR 3\) |
| **데이터 검색 (Retrieval)** | Q6(관련성)을 어떻게 극대화할까? (시맨틱 \+ 키워드) | '하이브리드 검색' (Vector \+ Keyword), '2단계 재순위 모델' | (BM25 \+ Milvus) \+ Cohere ReRank 모델 |
| **데이터 삭제 (Deletion)** | Q4('망각')을 법적/기술적(노이즈)으로 어떻게 구현할까? | '메타데이터 플래그' (Soft Delete) 또는 'ID 기반 즉시 삭제' (Hard Delete) | is\_deleted 메타데이터 필터링 또는 Milvus delete() API 호출 |

